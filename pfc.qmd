---
title: "Prepare for Class"
author: "Abigail Burns"
format: html
editor: visual
---

### Natural Language Basics

#### [Stages of NLP:]{.underline}

1.  Sentence Segmentation
2.  Word Tokenization
3.  Text Lemmatization
4.  Stop Words
5.  Dependency Parsing
6.  Named Entity Recognition (NER)
7.  Coreference Resolution

#### [Vocab/Terminology:]{.underline}

-   TF-IDF (Term Frequency-Inverse Document Frequency): statistical measure used to evaluate the importance of a word in a document relative to a collection of documents; considers words' frequency across the entire corpus

    -   Cons: lacks semantic understanding, doesn't account for word order

    -   Alternatives: word embedding (e.g. Word2Vec)

-   RSS (Really Simple Syndication): method of summarizing updates and information from online sources in a lightweight form (usually XML)

-   AGI (Artificial General Intelligence): machine with strong or human-level intelligence, capable of general cognitive abilities including reasoning, problem-solving, perception, learning, and language comprehension

-   Foundation Model: large, pre-trained neural network that can be adapted for various tasks

-   RAG (Retrieval-Augmented Generation): machine learning technique that enhances the accuracy and relevant of large language models (LLMs) by incorporating information from external knowledge bases

    -   Retrieval: mechanism to find relevant information from external sources like databases, documents, or web pages

    -   Contextualization: retrieved information is combined with user's original query

    -   Generalization: LLM uses combined information to generate a response that is more accurate and relevant to the user's question
